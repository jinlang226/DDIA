# 记录和衍生数据系统

存储和处理数据的系统可以分为两大类

## 记录系统（System of record）
也被称为真相源（source of truth），持有数据的权威版本

## 衍生数据系统（Derived data systems）
* 衍生系统中的数据，通常是另一个系统中的现有数据以某种方式进行转换或处理的结果。如果丢失衍生数据，可以从原始来源重新创建。典型的例子是缓存（cache）
* 因为它明确了系统中的数据流：系统的哪一部分具有哪些输入和哪些输出，以及它们如何相互依赖。

***

# 批处理
* 服务（在线系统） Services (online systems)
  * 响应时间通常是服务性能的主要衡量指标，可用性通常非常重要
* 批处理系统（离线系统） Batch processing systems (offline systems)
  * 批量作业通常会定期运行
* 流处理系统（准实时系统） Stream processing systems (near-real-time systems)

# 使用Unix工具的批处理 Batch Processing with Unix Tools

## 分析简单日志 Simple Log Analysis

### 命令链与自定义程序 Chain of commands versus custom program

### 排序 VS 内存中的聚合 Sorting versus in-memory aggregation

## Unix哲学 The Unix Philosophy
* 这种方法 —— 自动化，快速原型设计，增量式迭代，对实验友好，将大型项目分解成可管理的块 —— 听起来非常像今天的敏捷开发和DevOps运动。奇怪的是，四十年来变化不大。
* 尽管这些程序中有很多是由不同人群编写的，但它们可以灵活地结合在一起。 Unix如何实现这种可组合性？

### 统一的接口 A uniform interface
* 如果你希望一个程序的输出成为另一个程序的输入，那意味着这些程序必须使用相同的数据格式
* 即使是具有相同数据模型的数据库，将数据从一种导出再导入另一种也并不容易。缺乏整合导致了数据的巴尔干化（一个国家或政区分裂成多个互相敌对的国家或政区的过程）。

### 逻辑与布线相分离 Separation of logic and wiring
* Unix工具的另一个特点是使用标准输入（stdin）和标准输出（stdout）
* 管道允许你将一个进程的标准输出附加到另一个进程的标准输入
* 这允许shell用户以任何他们想要的方式连接输入和输出；该程序不知道或不关心输入来自哪里以及输出到哪里。 （人们可以说这是一种松耦合（loose coupling），晚期绑定（late binding）【15】或控制反转（inversion of control）【16】）。将输入/输出布线与程序逻辑分开，可以将小工具组合成更大的系统。

### 透明度和实验 Transparency and experimentation
Unix工具的最大局限在于它们只能在一台机器上运行 —— 而Hadoop这样的工具即应运而生

# MapReduce和分布式文件系统
MapReduce有点像Unix工具，但分布在数千台机器上。它接受一个或多个输入，并产生一个或多个输出。

## MapReduce Job Execution
* ​ MapReduce是一个编程框架，你可以使用它编写代码来处理HDFS（Hadoop分布式文件系统）等分布式文件系统中的大型数据集。
* 实现两个回调函数，Mapper和Reducer：
  * Mapper：Mapper会在每条输入记录上调用一次，其工作是从输入记录中提取键值。
  * Reducer：Reducer可以产生输出记录（例如相同URL的出现次数
* Mapper的作用是将数据放入一个适合排序的表单中，并且Reducer的作用是处理已排序的数据。

### Distributed execution of MapReduce
* MapReduce可以在多台机器上并行执行计算

### MapReduce workflows
* ​ 因此，被链接的MapReduce作业并没有那么像Unix命令管道（它直接将一个进程的输出作为另一个进程的输入，仅用一个很小的内存缓冲区）。它更像是一系列命令，其中每个命令的输出写入临时文件，下一个命令从临时文件中读取。这种设计有利也有弊，我们将在“物化中间状态”中讨论。

## Reduce端连接与分组 Reduce-Side Joins and Grouping
当MapReduce作业被赋予一组文件作为输入时，它读取所有这些文件的全部内容；数据库会将这种操作称为全表扫描。如果你只想读取少量的记录，则全表扫描与索引查询相比，代价非常高昂。但是在分析查询中（参阅“事务处理或分析？”），通常需要计算大量记录的聚合。在这种情况下，特别是如果能在多台机器上并行处理时，扫描整个输入可能是相当合理的事情。

### 示例：分析用户活动事件 Example: analysis of user activity events
获取用户数据库的副本（例如，使用ETL进程从数据库备份中提取数据，参阅“数据仓库”），并将它和用户行为日志放入同一个分布式文件系统中。然后你可以将用户数据库存储在HDFS中的一组文件中，而用户活动记录存储在另一组文件中，并能用MapReduce将所有相关记录集中到同一个地方进行高效处理。

### 排序合并连接 Sort-merge joins
​ 由于Reducer一次处理一个特定用户ID的所有记录，因此一次只需要将一条用户记录保存在内存中，而不需要通过网络发出任何请求。这个算法被称为排序合并连接（sort-merge join），因为Mapper的输出是按键排序的，然后Reducer将来自连接两侧的有序记录列表合并在一起。

### Bringing related data together in the same place
​使用MapReduce编程模型，能将计算的物理网络通信层面（从正确的机器获取数据）从应用逻辑中剥离出来（获取数据后执行处理）。这种分离与数据库的典型用法形成了鲜明对比

### GROUP BY
* 如果你有多个Web服务器处理用户请求，则特定用户的活动事件很可能分散在各个不同的服务器的日志文件中。你可以通过使用session cookie，用户ID或类似的标识符作为分组键，以将特定用户的所有活动事件放在一起来实现会话化，与此同时，不同用户的事件仍然散步在不同的分区中。
* Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中；Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。

### Handling skew
* 如果存在与单个键关联的大量数据，则“将具有相同键的所有记录放到相同的位置”这种模式就被破坏了。
* 不成比例的活动数据库记录被称为关键对象（linchpin object）【38】或热键（hot key）。
* 将处理热键的工作分散到多个Reducer上，这样可以使其更好地并行化，代价是需要将连接另一侧的输入记录复制到多个Reducer上。 Crunch中的分片连接（sharded join）方法与之类似，但需要显式指定热键而不是使用采样作业。
*  Hive的偏斜连接优化采取了另一种方法。它需要在表格元数据中显式指定热键，并将与这些键相关的记录单独存放，与其它文件分开。当在该表上执行连接时，对于热键，它会使用Map端连接

## Map-Side Joins
Mapper扮演着预处理输入数据的角色：从每个输入记录中提取键值，将键值对分配给Reducer分区，并按键排序。

### 广播散列连接 Broadcast hash joins
* 适用于执行Map端连接的最简单场景是大数据集与小数据集连接的情况。要点在于小数据集需要足够小，以便可以将其全部加载到每个Mapper的内存中。
* ​ 这种简单有效的算法被称为广播散列连接（broadcast hash join）：广播一词反映了这样一个事实，每个连接较大输入端分区的Mapper都会将较小输入端数据集整个读入内存中（所以较小输入实际上“广播”到较大数据的所有分区上），散列一词反映了它使用一个散列表。 

### 分区散列连接 Partitioned hash joins

### Map端合并连接 MapReduce workflows with map-side joins
如果输入数据集不仅以相同的方式进行分区，而且还基于相同的键进行排序，则可适用另一种Map端联接的变体。

### MapReduce工作流与Map端连接 MapReduce workflows with map-side joins
​如果Map端连接的输入以相同的方式进行分区，则散列连接方法可以独立应用于每个分区。

## 批处理工作流的输出 The Output of Batch Workflows
批处理过程的输出通常不是报表，而是一些其他类型的结构。

### 建立搜索索引 Building search indexes
* Google最初使用MapReduce是为其搜索引擎建立索引，用了由5到10个MapReduce作业组成的工作流实现
* 如果需要对一组固定文档执行全文搜索，则批处理是一种构建索引的高效方法：Mapper根据需要对文档集合进行分区，每个Reducer构建该分区的索引，并将索引文件写入分布式文件系统。构建这样的文档分区索引（参阅“分区和二级索引”）并行处理效果拔群。

### 键值存储作为批处理输出
* 搜索索引只是批处理工作流可能输出的一个例子。批处理的另一个常见用途是构建机器学习系统，例如分类器（比如垃圾邮件过滤器，异常检测，图像识别）与推荐系统（例如，你可能认识的人，你可能感兴趣的产品或相关的搜索
* 批处理过程的输出如何回到Web应用可以查询的数据库中呢？
  * 在批处理作业内创建一个全新的数据库，并将其作为文件写入分布式文件系统中作业的输出目录，就像上节中的搜索索引一样。

### 批处理输出的哲学 Philosophy of batch process outputs
* 输入保持不变，任何先前的输出都被新输出完全替换，且没有其他副作用。这意味着你可以随心所欲地重新运行一个命令，略做改动或进行调试，而不会搅乱系统的状态。
* 通过将输入视为不可变且避免副作用（如写入外部数据库），批处理作业不仅实现了良好的性能，而且更容易维护
* 在Hadoop上可以通过使用更结构化的文件格式消除一些低价值的语法转换：比如Avro（参阅“Avro”）和Parquet（参阅“列存储”）经常使用，因为它们提供了基于模式的高效编码，并允许模式随时间推移而演进

## Hadoop与分布式数据库的对比
* Hadoop有点像Unix的分布式版本，其中HDFS是文件系统，而MapReduce是Unix进程的怪异实现（总是在Map阶段和Reduce阶段运行sort工具）
* 大规模并行处理（MPP， massively parallel processing）专注于在一组机器上并行执行分析SQL查询，而MapReduce和分布式文件系统的组合则更像是一个可以运行任意程序的通用操作系统。

### 存储多样性
* 分布式文件系统中的文件只是字节序列，可以使用任何数据模型和编码来编写。可能是数据库记录的集合，但同样可以是文本，图像，视频，传感器读数，稀疏矩阵，特征向量，基因组序列或任何其他类型的数据。
* 相比之下，在将数据导入数据库专有存储格式之前，MPP数据库通常需要对数据和查询模式进行仔细的前期建模。MPP数据库所要求的谨慎模式设计拖慢了集中式数据收集速度
* 以原始形式收集数据，稍后再操心模式的设计，能使数据收集速度加快（有时被称为“数据湖（data lake）”或“企业数据中心（enterprise data hub）”。数据集的生产者不再需要强制将其转化为标准格式，数据的解释成为消费者的问题
* 因此，Hadoop经常被用于实现ETL过程（参阅“数据仓库”）：事务处理系统中的数据以某种原始形式转储到分布式文件系统中，然后编写MapReduce作业来清理数据，将其转换为关系形式，并将其导入MPP数据仓库以进行分析。

### 处理模型多样性 Diversity of processing models
山东分公司风蛋糕

### 针对频繁故障设计

# MapReduce之后

## 物化中间状态

### 数据流引擎

### 容错

### 关于物化的讨论

## 图与迭代处理

### Pregel处理模型

### 容错

### 并行执行

## 高级API和语言

### 向声明式查询语言的转变

### 专业化的不同领域


