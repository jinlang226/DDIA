# 流处理
在本章中，我们将把事件流（event stream）视为一种数据管理机制：无界限，增量处理，与上一章中批量数据相对应。

***

# 传递事件流 Transmitting Event Streams
在批处理中，文件被写入一次，然后可能被多个作业读取。类似地，在流处理术语中，一个事件由 生产者（producer） （也称为 发布者（publisher） 或 发送者（sender） ）生成一次，然后可能由多个 消费者（consumer） （ 订阅者（subscribers） 或 接收者（recipients） ）进行处理。在文件系统中，文件名标识一组相关记录；在流式系统中，相关的事件通常被聚合为一个 主题（topic） 或 流（stream） 。

## 消息系统 Messaging Systems
* 向消费者通知新事件的常用方式是使用消息传递系统（messaging system）：生产者发送包含事件的消息，然后将消息推送给消费者
* 在这个发布/订阅模式中
  * 如果生产者发送消息的速度比消费者能够处理的速度快会发生什么？
    * 有三种选择：系统可以丢掉消息，将消息放入缓冲队列，或使用背压（backpressure）（也称为流量控制（flow control）；即阻塞生产者，以免其发送更多的消息）。
  * 如果节点崩溃或暂时脱机，会发生什么情况？ —— 是否会有消息丢失？
    * 与数据库一样，持久性可能需要写入磁盘和/或复制的某种组合（参阅“复制和持久性”），这是有代价的。如果你能接受有时消息会丢失，则可能在同一硬件上获得更高的吞吐量和更低的延迟。

### 直接从生产者传递给消费者 Direct messaging from producers to consumers
* 许多消息传递系统使用生产者和消费者之间的直接网络通信，而不通过中间节点
* 尽管这些直接消息传递系统在设计它们的环境中运行良好，但是它们通常要求应用代码意识到消息丢失的可能性。它们的容错程度极为有限：即使协议检测到并重传在网络中丢失的数据包，它们通常也只是假设生产者和消费者始终在线。

### 消息代理 Message brokers
* 一种针对处理消息流而优化的数据库。它作为服务器运行，生产者和消费者作为客户端连接到服务器
* 通过将数据集中在代理上，这些系统可以更容易地容忍来来去去的客户端（连接，断开连接和崩溃），而持久性问题则转移到代理的身上。一些消息代理只将消息保存在内存中，而另一些消息代理（取决于配置）将其写入磁盘，以便在代理崩溃的情况下不会丢失。
* 排队的结果是，消费者通常是异步（asynchronous）的

### 消息代理与数据库对比 Message brokers compared to databases
* 数据库通常保留数据直至显式删除，而大多数消息代理在消息成功递送给消费者时会自动删除消息
* 大多数消息代理都认为它们的工作集相当小—— 即队列很短
* 数据库通常支持二级索引和各种搜索数据的方式，而消息代理通常支持按照某种模式匹配主题，订阅其子集。
* 相比之下，消息代理不支持任意查询，但是当数据发生变化时（即新消息可用时），它们会通知客户端。
* 这是关于消息代理的传统观点，它被封装在诸如JMS和AMQP的标准中，并且被诸如RabbitMQ，ActiveMQ，HornetQ，Qpid，TIBCO企业消息服务，IBM MQ，Azure Service Bus和Google Cloud Pub/Sub实现。

### 多个消费者 Multiple consumers
* 负载均衡（load balance）
  * 每条消息都被传递给消费者之一，所以处理该主题下消息的工作能被多个消费者共享。代理可以为消费者任意分配消息。
* 扇出（fan-out）
  * 每条消息都被传递给所有消费者。扇出允许几个独立的消费者各自“收听”相同的消息广播，而不会相互影响 —— 这个流处理中的概念对应批处理中多个不同批处理作业读取同一份输入文件
两种模式可以组合使用：例如，两个独立的消费者组可以每组各订阅一个主题，每一组都共同收到所有消息，但在每一组内部，每条消息仅由单个节点处理。

### 确认与重新交付 Acknowledgments and redelivery
* 为了确保消息不会丢失，消息代理使用确认（acknowledgments）：客户端必须显式告知代理消息处理完毕的时间，以便代理能将消息从队列中移除。
* 即使消息代理试图保留消息的顺序（如JMS和AMQP标准所要求的），负载均衡与重传的组合也不可避免地导致消息被重新排序。为避免此问题，你可以让每个消费者使用单独的队列（即不使用负载均衡功能）。如果消息是完全独立的，则消息顺序重排并不是一个问题。但正如我们将在本章后续部分所述，如果消息之间存在因果依赖关系，这就是一个很重要的问题。

## 分区日志 Partitioned Logs
* 通过网络发送数据包或向网络服务发送请求通常是短暂的操作，不会留下永久的痕迹
* 数据库和文件系统采用截然相反的方法论：至少在某人显式删除前，通常写入数据库或文件的所有内容都要被永久记录下来。
* 而 AMQP/JMS风格的消息传递并非如此：收到消息是具有破坏性的，因为确认可能导致消息从代理中被删除，因此你不能期望再次运行同一个消费者能得到相同的结果；作为对比，你可以随时为文件和数据库添加新的客户端，且能读取任意久远的数据（只要应用没有显式覆盖或删除这些数据）
* 把它俩杂交一下，既有数据库的持久存储方式，又有消息传递的低延迟通知？这就是基于日志的消息代理（log-based message brokers） 背后的想法。

### Using logs for message storage
* 日志只是磁盘上简单的仅追加记录序列
* 生产者通过将消息追加到日志末尾来发送消息，而消费者通过依次读取日志来接收消息。
* 为了扩展到比单个磁盘所能提供的更高吞吐量，可以对日志进行分区
* 在每个分区内，代理为每个消息分配一个单调递增的序列号或偏移量（offset）

### 日志与传统消息相比 Logs compared to traditional messaging
* 基于日志的方法天然支持扇出式消息传递，因为多个消费者可以独立读取日志，而不会相互影响 —— 读取消息不会将其从日志中删除。为了在一组消费者之间实现负载平衡，代理可以将整个分区分配给消费者组中的节点，而不是将单条消息分配给消费者客户端。

### 消费者偏移量 Consumer offsets
* 如果只追加写入日志，则磁盘空间终究会耗尽。为了回收磁盘空间，日志实际上被分割成段，并不时地将旧段删除或移动到归档存储。
* 日志实现了一个有限大小的缓冲区，当缓冲区填满时会丢弃旧消息，它也被称为循环缓冲区（circular buffer）或环形缓冲区（ring buffer）。不过由于缓冲区在磁盘上，因此可能相当的大。
* 当这些系统开始写入磁盘时，就要慢的多，所以吞吐量取决于保留的历史数量。

### 磁盘空间使用 Disk space usage
日志实现了一个有限大小的缓冲区，当缓冲区填满时会丢弃旧消息，它也被称为循环缓冲区（circular buffer）或环形缓冲区（ring buffer）。不过由于缓冲区在磁盘上，因此可能相当的大。

### 当消费者跟不上生产者时 When consumers cannot keep up with producers
* 三种选择：丢弃信息，进行缓冲或施加背压。在这种分类法里，基于日志的方法是缓冲的一种形式，具有很大，但大小固定的缓冲区（受可用磁盘空间的限制）。
* 你可以监控消费者落后日志头部的距离，如果落后太多就发出报警。由于缓冲区很大，因而有足够的时间让人类运维来修复慢消费者，并在消息开始丢失之前让其赶上。
* 即使消费者真的落后太多开始丢失消息，也只有那个消费者受到影响；它不会中断其他消费者的服务。这是一个巨大的运维优势：你可以实验性地消费生产日志，以进行开发，测试或调试，而不必担心会中断生产服务。当消费者关闭或崩溃时，会停止消耗资源，唯一剩下的只有消费者偏移量。

### 重播旧信息 Replaying old messages
* 在基于日志的消息代理中，使用消息更像是从文件中读取数据：这是只读操作，不会更改日志。
* ​这一方面使得基于日志的消息传递更像上一章的批处理，其中衍生数据通过可重复的转换过程与输入数据显式分离。它允许进行更多的实验，更容易从错误和漏洞中恢复，使其成为在组织内集成数据流的良好工具

# 流与数据库 Databases and Streams
* 从消息传递和流中获取灵感，并将它们应用于数据库
* 在本节中，我们将首先看看异构数据系统中出现的一个问题，然后探讨如何通过将事件流的想法带入数据库来解决这个问题。

## 保持系统同步 Keeping Systems in Sync
* 如果周期性的完整数据库转储过于缓慢，有时会使用的替代方法是双写（dual write），其中应用代码在数据变更时明确写入每个系统：例如，首先写入数据库，然后更新搜索索引，然后使缓存项失效（甚至同时执行这些写入）。
* 但是，双写有一些严重的问题，其中一个是竞争条件
* 双重写入的另一个问题是，其中一个写入可能会失败，而另一个成功。

## 变更数据捕获 Change Data Capture(CDC)
* 这是一种观察写入数据库的所有数据变更，并将其提取并转换为可以复制到其他系统中的形式的过程。 CDC是非常有意思的，尤其是当变更能在被写入后立刻用于流时。
* 你可以捕获数据库中的变更，并不断将相同的变更应用至搜索索引。如果变更日志以相同的顺序应用，则可以预期搜索索引中的数据与数据库中的数据是匹配的。

### 变更数据捕获的实现 Implementing change data capture
* We can call the log consumers derived data systems
* 变更数据捕获使得一个数据库成为领导者（被捕获变化的数据库），并将其他组件变为追随者。基于日志的消息代理非常适合从源数据库传输变更事件，因为它保留了消息的顺序
* ​像消息代理一样，变更数据捕获通常是异步的：记录数据库系统不会等待消费者应用变更再进行提交。这种设计具有的运维优势是，添加缓慢的消费者不会过度影响记录系统。不过，所有复制延迟可能有的问题在这里都可能出现

### 初始快照 Initial snapshot
如果你没有完整的历史日志，则需要从一个一致的快照开始，如先前上的“设置新的从库”中所述

### 日志压缩 Log compaction
* 如果你只能保留有限的历史日志，则每次要添加新的衍生数据系统时，都需要做一次快照。但日志压缩（log compaction） 提供了一个很好的备选方案。
* 如果CDC系统被配置为，每个变更都包含一个主键，且每个键的更新都替换了该键以前的值，那么只需要保留对键的最新写入就足够了。
* 无论何时需要重建衍生数据系统（如搜索索引），可以从压缩日志主题0偏移量处启动新的消费者，然后依次扫描日志中的所有消息。日志能保证包含数据库中每个键的最新值（也可能是一些较旧的值）—— 换句话说，你可以使用它来获取数据库内容的完整副本，而无需从CDC源数据库取一个快照。

### 变更流的API支持 API support for change streams
* 越来越多的数据库开始将变更流作为第一类的接口

## 事件溯源 Event Sourcing
* 领域驱动设计（domain-driven design, DDD） 社区中折腾出来的技术
* 事件溯源涉及到将所有对应用状态的变更存储为变更事件日志
* 应用层面：
  * 在变更数据捕获中，应用以可变方式（mutable way） 使用数据库，任意更新和删除记录。
  * 在事件溯源中，应用逻辑显式构建在写入事件日志的不可变事件之上。
* 事件源是一种强大的数据建模技术：从应用的角度来看，将用户的行为记录为不可变的事件更有意义，而不是在可变数据库中记录这些行为的影响。
* 事件溯源类似于编年史（chronicle） 数据模型，事件日志与星型模式中的事实表之间也存在相似之处

### 从事件日志中派生出当前状态 Deriving current state from the event log
* 事件日志本身并不是很有用，因为用户通常期望看到的是系统的当前状态，而不是变更历史。例如，在购物网站上，用户期望能看到他们购物车里的当前内容，而不是他们购物车所有变更的一个仅追加列表
* 重放事件日志允许让你重新构建系统的当前状态。不过，日志压缩需要采用不同的方式处理：
  * 用于记录更新的CDC事件通常包含记录的完整新版本，因此主键的当前值完全由该主键的最近事件确定，而日志压缩可以丢弃相同主键的先前事件。
  * 另一方面，事件溯源在更高层次进行建模：事件通常表示用户操作的意图，而不是因为操作而发生的状态更新机制。在这种情况下，后面的事件通常不会覆盖先前的事件，所以你需要完整的历史事件来重新构建最终状态。这里进行同样的日志压缩是不可能的。

### 命令和事件 Commands and events
* 事件溯源的哲学是仔细区分事件（event）和命令（command）。刚开始是一个命令验证成功且命令被接收之后，他成为一个持久化且不变的事件。
* 在事件生成的时刻，它就成为了事实（fact）。
* 事件流的消费者不允许拒绝事件：当消费者看到事件时，它已经成为日志中不可变的一部分，并且可能已经被其他消费者看到了。因此任何对命令的验证，都需要在它成为事件之前同步完成。

## 状态，流和不变性 State, Streams, and Immutability
* 这种不变性原则（文件不变性）也是使得事件溯源与变更数据捕获如此强大的原因。
* 我们通常将数据库视为应用程序当前状态的存储。（状态的本质是，它会变化，所以数据库才会支持数据的增删改。这又是如何符合不变性的呢？）
* 所有变化的日志—— 变化日志（change log），表示了随时间演变的状态。
* $$ state(now) = \int_{t=0}^{now}{stream(t) \ dt} $$
* $$ stream(t) = \frac{d\ state(t)}{dt} $$ 

### 不可变事件的优点 Advantages of immutable events
* 数据库中的不变性是一个古老的概念
* 如果你意外地部署了将错误数据写入数据库的错误代码，当代码会破坏性地覆写数据时，恢复要困难得多。使用不可变事件的仅追加日志，诊断问题与故障恢复就要容易的多。
* 不可变的事件也包含了比当前状态更多的信息。比如添加购物车再移除

### 从同一事件日志中派生多个视图 Deriving several views from the same event log
* 添加从事件日志到数据库的显式转换，能够使应用更容易地随时间演进
* 通过将数据写入的形式与读取形式相分离，并允许几个不同的读取视图，你能获得很大的灵活性。这个想法有时被称为命令查询责任分离（command query responsibility segregation, CQRS）
* 在针对读取优化的视图中对数据进行非规范化是完全合理的，因为翻译过程提供了使其与事件日志保持一致的机制。

### 并发控制 Concurrency control
* 一种解决方案是将事件附加到日志时同步执行读取视图的更新。而将这些写入操作合并为一个原子单元需要事务，所以要么将事件日志和读取视图保存在同一个存储系统中，要么就需要跨不同系统进行分布式事务。
* 从事件日志导出当前状态也简化了并发控制的某些部分。通过事件溯源，你可以设计一个自包含的事件以表示一个用户操作。然后用户操作就只需要在一个地方进行单次写入操作 —— 即将事件附加到日志中 —— 这个还是很容易使原子化的。

### 不变性的限制 Limitations of immutability
* 许多不使用事件溯源模型的系统也还是依赖不可变性：各种数据库在内部使用不可变的数据结构或多版本数据来支持时间点快照。 Git，Mercurial和Fossil等版本控制系统也依靠不可变的数据来保存文件的版本历史记录。
* ​ 真正删除数据是非常非常困难的【64】，因为副本可能存在于很多地方：例如，存储引擎，文件系统和SSD通常会向一个新位置写入，而不是原地覆盖旧数据【52】，而备份通常是特意做成不可变的，防止意外删除或损坏。

# 流处理 Processing Streams
* 可以用流做什么
  1. 你可以将事件中的数据写入数据库，缓存，搜索索引或类似的存储系统，然后能被其他客户端查询。
  2. 你能以某种方式将事件推送给用户，人是流的最终消费者。
  3. 你可以处理一个或多个输入流，并产生一个或多个输出流。流可能会经过由几个这样的处理阶段组成的流水线，最后再输出（选项1或2）
* 与批量作业相比的一个关键区别是，流不会结束。排序对无界数据集没有意义，因此无法使用排序合并联接
* 容错机制也必须改变：对于已经运行了几分钟的批处理作业，可以简单地从头开始重启失败任务，但是对于已经运行数年的流作业，重启后从头开始跑可能并不是一个可行的选项。

## 流处理的应用 Uses of Stream Processing
流处理一直用于监控目的，如果某个事件发生，单位希望能得到警报

### 复合事件处理 Complex event processing(CEP)
* CEP允许你指定规则以在流中搜索某些事件模式
* CEP系统通常使用高层次的声明式查询语言，比如SQL，或者图形用户界面，来描述应该检测到的事件模式。这些查询被提交给处理引擎，该引擎消费输入流，并在内部维护一个执行所需匹配的状态机。当发现匹配时，引擎发出一个复合事件（complex event）（因此得名），并附有检测到的事件模式详情【67】。
* CEP引擎反转了角色：查询是长期存储的，来自输入流的事件不断流过它们，搜索匹配事件模式的查询
* ​CEP的实现包括Esper 【69】，IBM InfoSphere Streams 【70】，Apama，TIBCO StreamBase和SQLstream。像Samza这样的分布式流处理组件，支持使用SQL在流上进行声明式查询

### 流分析 Stream analytics
* CEP与流分析之间的边界是模糊的，但一般来说，分析往往对找出特定事件序列并不关心，而更关注大量事件上的聚合与统计指标
* 这些统计值通常是在固定时间区间内进行计算的
*  流分析系统有时会使用概率算法
*  使用近似算法有时让人们觉得流处理系统总是有损的和不精确的，但这是错误看法：流处理并没有任何内在的近似性，而概率算法只是一种优化
*  许多开源分布式流处理框架的设计都是针对分析设计的：例如Apache Storm，Spark Streaming，Flink，Concord，Samza和Kafka Streams 【74】。托管服务包括Google Cloud Dataflow和Azure Stream Analytics。

### 维护物化视图 Maintaining materialized views
* 在事件溯源中，应用程序的状态是通过应用（apply）事件日志来维护的；这里的应用状态也是一种物化视图。与流分析场景不同的是，仅考虑某个时间窗口内的事件通常是不够的：构建物化视图可能需要任意时间段内的所有事件，除了那些可能由日志压缩丢弃的过时事件。
* 需要一个可以一直延伸到时间开端的窗口

### 在流上搜索 Search on streams
* Besides CEP, which allows searching for patterns consisting of multiple events, there is also sometimes a need to search for individual events based on complex criteria, such as full-text search queries.
* 传统的搜索引擎首先索引文件，然后在索引上跑查询。相比之下，搜索一个数据流则反了过来：查询被存储下来，文档从查询中流过，就像在CEP中一样。在简单的情况就是，你可以为每个文档测试每个查询。但是如果你有大量查询，这可能会变慢。为了优化这个过程，可以像对文档一样，为查询建立索引。因而收窄可能匹配的查询集合

### 消息传递和RPC Message passing and RPC
* RPC类系统与流处理之间有一些交叉领域。例如，Apache Storm有一个称为分布式RPC的功能，它允许将用户查询分散到一系列也处理事件流的节点上；然后这些查询与来自输入流的事件交织，而结果可以被汇总并发回给用户
* ​也可以使用Actor框架来处理流。但是，很多这样的框架在崩溃时不能保证消息的传递，除非你实现了额外的重试逻辑，否则这种处理不是容错的。

## 时间推理 Reasoning About Time
* 而且使用事件中的时间戳，使得处理是确定性的：在相同的输入上再次运行相同的处理过程会得到相同的结果
* 许多流处理框架使用处理机器上的本地系统时钟（处理时间（processing time））来确定窗口 windowing。然而，如果存在任何显著的处理延迟 —— 即，事件处理显著地晚于事件实际发生的时间，处理就失效了。

### 事件时间与处理时间 Event time versus processing time
很多原因都可能导致处理延迟：排队，网络故障（参阅“不可靠的网络”），性能问题导致消息代理/消息处理器出现争用，流消费者重启，重新处理过去的事件（参阅“重放旧消息”），或者在修复代码BUG之后从故障中恢复。

### 知道什么时候准备好了
用事件时间来定义窗口的一个棘手的问题是，你永远也无法确定是不是已经收到了特定窗口的所有事件，还是说还有一些事件正在来的路上。

### 你用的是谁的时钟？
* 当事件可能在系统内多个地方进行缓冲时，为事件分配时间戳更加困难了
* 要校正不正确的设备时钟，一种方法是记录三个时间戳：
  * 事件发生的时间，取决于设备时钟
  * 事件发送往服务器的时间，取决于设备时钟
  * 事件被服务器接收的时间，取决于服务器时钟
* 通过从第三个时间戳中减去第二个时间戳，可以估算设备时钟和服务器时钟之间的偏移。然后可以将该偏移应用于事件时间戳，从而估计事件实际发生的真实时间

### 窗口的类型
如何定义时间段的窗口

#### 滚动窗口（Tumbling Window）
滚动窗口有着固定的长度，每个事件都仅能属于一个窗口。

#### 滑动窗口（Sliding Window）
包含彼此艰巨在特定时常内的所有事件

#### 会话窗口（Session window）
无特定时常

## 流式连接 Stream Joins
新事件随时可能出现在一个流中，这使得流连接要比批处理连接更具挑战性。

### 流流连接（窗口连接） Stream-stream join (window join)
流处理器需要维护状态

### 流表连接（流扩展）Stream-table join (stream enrichment)
流处理器可以订阅用户档案数据库的更新日志，如同活跃事件流一样。当增添或修改档案时，流处理器会更新其本地副本。因此，我们有了两个流之间的连接：活动事件和档案更新。

### 表表连接（维护物化视图） Table-table join (materialized view maintenance)
* 当用户想要查看他们的主页时间线时，迭代用户所关注人群的推文并合并它们是一个开销巨大的操作
* 要在流处理器中实现这种缓存维护，你需要推文事件流（发送与删除）和关注关系事件流

### 连接的时间依赖性 Time-dependence of joins
* 它们都需要流处理器维护连接一侧的一些状态（搜索与点击事件，用户档案，关注列表），然后当连接另一侧的消息到达时查询该状态。
* 缓慢变化的维度（slowly changing dimension, SCD），通常通过对特定版本的记录使用唯一的标识符来解决

## 容错 Fault Tolerance
看起来好像每条输入记录都被处理了恰好一次 —— 没有记录被跳过，而且没有记录被处理两次。恰好一次语义（exactly-once semantics），尽管有效一次（effectively-once） 可能会是一个更写实的术语

### 微批量与存档点 Microbatching and checkpointing
* 一个解决方案是将流分解成小块，并像微型批处理一样处理每个块。这种方法被称为微批次（microbatching），它被用于Spark Streaming
* Apache Flink则使用不同的方法，它会定期生成状态的滚动存档点并将其写入持久存储【92,93】。如果流算子崩溃，它可以从最近的存档点重启，并丢弃从最近检查点到崩溃之间的所有输出。存档点会由消息流中的 壁障（barrier） 触发，类似于微批次之间的边界，但不会强制一个特定的窗口大小。
* 微批次与存档点方法提供了与批处理一样的恰好一次语义。但是，只要输出离开流处理器（例如，写入数据库，向外部消息代理发送消息，或发送电子邮件），框架就无法抛弃失败批次的输出了。在这种情况下，重启失败任务会导致外部副作用发生两次，只有微批次或存档点不足以阻止这一问题。

### 原子提交再现 Atomic commit revisited
* ​为了在出现故障时表现出恰好处理一次的样子，我们需要确保事件处理的所有输出和副作用当且仅当处理成功时才会生效。
* ​ 这些事情要么都原子地发生，要么都不发生，但是它们不应当失去同步。
* 通过在流处理框架中同时管理状态变更与消息传递来内化事务。事务协议的开销可以通过在单个事务中处理多个输入消息来分摊。

### 幂等性 Idempotence
* 我们的目标是丢弃任何失败任务的部分输出，以便能安全地重试，而不会生效两次。分布式事务是实现这个目标的一种方式，而另一种方式是依赖幂等性（idempotence）
* 幂等操作是多次重复执行与单次执行效果相同的操作。
* 当从一个处理节点故障切换到另一个节点时，可能需要进行防护（fencing）（参阅“领导和锁”），以防止被假死节点干扰。尽管有这么多注意事项，幂等操作是一种实现恰好一次语义的有效方式，仅需很小的额外开销。

### 失败后重建状态
* 将状态保存在远程数据存储中，并进行复制，然而正如在“流表连接”中所述，每个消息都要查询远程数据库可能会很慢。
* 另一种方法是在流处理器本地保存状态，并定期复制。然后当流处理器从故障中恢复时，新任务可以读取状态副本，恢复处理而不丢失数据



